---
title: "Dynamic number of speculative tokens accelerates speculative decoding"
thumbnail: /blog/assets/optimum_intel/intel_thumbnail.png
authors:
- user: user1
  guest: true
  org: Intel
- user: user2
  guest: true
  org: Intel
---
# Dynamic number of speculative tokens accelerates speculative decoding

Speculative decoding is commonly used for reducing the inference latency of large language models. Its effectiveness depends highly on the speculation lookahead (SL)â€”the number of tokens generated by the draft model at each iteration. 

Transformers proposes two different methods to define the schedule at which max assistant tokens shall be changed during inference. The simple approach consists of generating a constant number of candidate tokens at each speculative iteration. Another approach, based on a heuristic, consists of adjusting the number of candidate tokens to be produced in the next iteration according to the acceptance rate of the current iteration. The number of candidate tokens increases when all speculative tokens are correct, and decreases in the other case.

We employ an oracle for detecting the optimal value of SL for each speculative iteration. The oracle uses the draft model to autoregressively generate tokens until a mismatch occurs between the predicted tokens of the draft and target models. 
We show in the figure below oracle and static SL values for different speculative iterations on one MBPP example. We observe a high variance of oracle SL values.  For static SL, we run 38 target forward passes and 192 draft forward passes, while for oracle SL, we only run 27 target forward passes and 129 draft forward passes. 

<p align="center">
    <img src="assets/dynamic_speculation_lookahead/oracle_K_2.png" width=500>
</p>
<p align="center">
    <em>IMAGE CAPTION HERE</em>
</p>

The figure below shows the average SL over the normalized index of the speculative iterations for the Alpaca dataset.

<p align="center">
    <img src="assets/dynamic_speculation_lookahead/Alpaca.png" width=500>
</p>
<p align="center">
    <em>IMAGE CAPTION HERE</em>
</p>

Both figures show a high variance of oracle SL values, implying that a static SL is likely to be suboptimal.

We introduce a simple method to dynamically set the SL value at each iteration. Immediately after generating any draft token, we decide whether the draft model should proceed and generate the next token or switch to the target model for verification, using assistant model confidence in its prediction, assistant_confidence_threshold. 
If the assistant model's confidence in its prediction for the current token is lower than a predefined threshold, the assistant model stops the current token generation iteration, even if the number of speculative tokens is not yet reached.

